%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[letterpaper,twoside,11pt]{article}

\input{plantilla.tex}

\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer
\fancyhead[L]{Jose Javier Gonzalez Ortiz}
\fancyhead[R]{EECS 587 : Parallel Computing} % Custom header text
\fancyfoot[RO,LE]{\thepage} % Custom footer text


\setlength{\parskip}{2mm}
\setlength{\headheight}{13.6pt}
%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\vspace{-15mm}\fontsize{24pt}{10pt}\selectfont\textbf{Parallel Implementation of Multiple Interdependent Lindenmayer Systems}} % Article title

\author{
\large
\textsc{Jose Javier Gonzalez Ortiz}\thanks{\href{mailto:jjgo@umich.edu}{jjgo@umich.edu}}\\[2mm] % Your name
\normalsize University of Michigan \\ % Your institution
% \normalsize \href{mailto:jjgo@umich.edu}{jjgo@umich.edu} % Your email address
% \vspace{-5mm}
}
\date{\today}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert title

\thispagestyle{fancy} % All pages have headers and footers

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\begin{abstract}

\noindent \lipsum[1] % Dummy abstract text

\end{abstract}

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\begin{multicols}{2} % Two-column layout throughout the main article text

\section{Introduction}
% \vspace{-6mm}
\lettrine[nindent=0em,lines=2]{M}
odern techniques for botanic and arboreal growth simulation rely in specific and dedicated models to correctly recreate the behavior of different types of plants. This creates a segmented and disconnected variety of models and techniques. As A. Lindenmayer and Przemyslaw described in \cite{Prusinkiewicz:1996:ABP:235579}, almost all botanical structures can be successfully model by Lindenmayer Systems.

However, raw L-Systems are not complex enough for this task and therefore we need to include both a parametric implementation to successfully model these types of structures. Moreover, parametric L-Systems in spite of depending on a number of initial parameters and conditions, they are deterministic. To cope with this limitation, we introduce randomness in the traditional form described in \cite{Prusinkiewicz:1996:ABP:235579}, by using Stochastic-Parametric L-Systems. This systems will have production rules that will not only rely on several parameters to correctly scalate the complexity of the system but will also apply this rules using a source of randomness to choose between a number of specified rules.

Another aspect we have to properly take into a account is the fact that botanical growth almost never occurs in a isolated fashion, and therefore we will be interested in looking at a framework that can accommodate the simultaneous derivation of multiple L-Systems. Having multiple stochastic L-Systems produces a non-realistic result as we will see later, so to compensate for this caveat we had to define the concept of Interdependent L-System.

In this paper we investigate the use of Interdependent L-System to realistically model the growth of a forest and we analyze several parallel implementations of this problem in a shared memory machine using OpenMP. L-Systems are parallel rewriting grammar which initially would seem to simplify the problem, but this derivation step leads to highly uneven amounts of work in a great number of scenarios. Furthermore, as we shall see later, adding the interdependence to the systems serializes the problem since after every timestep each system will need to communicate a number of metric to a variable number of other systems. This problem will produce a scenario experienced by a great amount of local simulation techniques.

We will introduce several parallel algorithms with increasing complexity and with increasing speedup and compare their behavior under different types of datasets, which from a simulation perspective would translate into different ecosystems. The final algorithm will involve calculating the connected components of the forest graph to initially subdivide the problem in equally complex albeit not equally balanced subproblems, and introduce a general approach to tackle this subproblems. To accomplish this, the algorithm will deserialize the time dimension by allowing some L-Systems to carry out further iterations as long as the correctness constraints are met. We will also analyze the bigger bottleneck of the algorithm and the way it tries to cope with the variability of input systems.

\textbf{Overview:} First  we will start by providing a background in canonical, parametric and stochastic L-Systems in Section \ref{sec:background}. Section \ref{sec:interdependence} will elaborate the model used to realistically model the problem and will discuss the serial implementation that was carried out. The parallel algorithms designed to solve this problem are discussed in Section \ref{sec:parallelization} and their associated results are shown in Section \ref{sec:results} and analyzed in Section \ref{sec:discussion}.

\subsection{Previous Work} % (fold)
\label{sub:previous_work}
\textbf{General L-Systems:} Prusinkiewicz and Lindenmayer gave the basic definition to the L-System algorithm and structure in \cite{Prusinkiewicz:1996:ABP:235579}. This was further extended by the work carried out in \cite{Parish:2001:PMC:383259.383292,Prusinkiewicz:1994:ST:192161.192254,Prusinkiewicz:2001:UPI:383259.383291}

\textbf{Parallelizing L-Systems:} Lacz and Hart introduced the use of manually written pixel shaders to compute L-Systems \cite{Lacz04proceduralgeometry}. A distributed memory approach making use up to 8 CPUs and the Message Passing Interface (MPI) was described in \cite{4392608}. An algorithm form the Parallel Generation of L-Systems was introduced by \cite{LIPP-2009-PGL}. The approach was appropriate for both GPU and multi-core CPUs, parallelizing both the derivation and interpretation of given L-Systems. The implementation provided was generic and supported parametric, stochastic and context sensitive productions. The work was further extended in \cite{LIPP-2010-PGMS} to make the algorithm work with multiple L-Systems.

\textbf{Forest Simulation:} L-Systems are within the most popular grammars to satisfactory model botanical structures. The definitions introduced by \cite{Prusinkiewicz:1996:ABP:235579} were later improved to more realistic three dimensional trees for \cite{4055766}. Since then, both models have been used in a number of forest growth models.

The model proposed by \cite{KurthSloboda2002} provides a wonderful framework to model the interdependence of L-Systems. Geometrical interpretation of parameters was used to calculate shadow cones and a carbon allocation economy was used to successfully control the growth of the trees. A later paper introduced a quasi-physical simulation of large-scale dynamic forest scenes by introducing a similar growth model and a wind field to account for environmental factors. Finally, \cite{Runions07modelingtrees} introduced a new model by employing a three dimensional version of the space colonization algorithm.
% subsection previous_work (end)

%------------------------------------------------

\section{Background} % (fold)
\label{sec:background}

\subsection{Definition} % (fold)
\label{sub:definition}

The work presented in this paper is based on L-systems so we will briefly introduce this modeling structure.

\emph{L-Systems:} are parallel rewriting systems and a type of formal grammar. L-systems are now commonly referred as \emph{parametric} L-systems, defined as a tuple:
\begin{equation}
	\textbf{G} = (V, \omega, P)
\end{equation}
where
\begin{compactitem}
\item $\textbf{V}$ (\emph{alphabet}) is a set of symbols containing the elements in the string that can be replaced
\item $\boldsymbol\omega$ (\emph{axiom}) is a string of symbols from $V$ defining the initial state of the system.
\item $\textbf{P}$ is a set of \emph{production rules} which define the way variables can be replaced with combinations of constants and variables. Each rule is composed by a \emph{predecessor} and a \emph{successor}. The successor will consist of a list of symbols that will replace the predecessor. Usually the predecessor contains only one symbol, if it involves more, the system is called \emph{context sensitive}. If a production rule is not specified for a symbol, the identity production is assumed.
\end{compactitem}

\emph{Parametric L-systems:} We can further expand the definition of L-system to accommodate parameters. In a parametric grammar, each symbol in the alphabet has a list of parameters associated with it. Parameters are usually real valued but there is not constraint in the mathematical structures that can be used. Production rules need to be extended to deal with parametric symbols. Parameters can be both \emph{global} or \emph{local} depending on if they belong to the current predecessor. Parameters are used in both conditional statements to choose between different production rules and for modifuying the parameters of the symbols in the successor. In the following example \eqref{eq:example}, we can see the behavior, where $g$ is a global parameter.
\begin{equation}
\label{eq:example}
	A(x,y) : x < 2 \quad\rightarrow\quad A(g,x+1) C B(3,y)
\end{equation}

\emph{Stochastic L-systems:} In order to deal with non-deterministic models, randomness can be introduced in the model by defining for each production rule $p \in P$ a set of production rules $\overline{p} = \{p_1,p_2\ldots p_k\}$ with associated probabilities $\overline{q} = \{q_1,q_2\ldots q_k\}$ and a random variable $R$ that will evaluate the rule $p$ as $p_i$ with probability $q_i$. This kind of grammars are tremendously useful when generating great amounts of L-systems, because otherwise all the elements in the group would look the same.

% subsection definition (end)

\subsection{Application} % (fold)
\label{sub:application}

Once defined the specific type of grammar or combination of grammars, to actually generate the geometry described by a L-System we have to execute two stages: the \emph{derivation} of the final symbol string and the \emph{interpretation} of such string to a particular geometry or structure.

\textbf{Derivation:} this phase involves a number of successive interpretation iterations. In each iteration, all symbols in the current state are translated in parallel using the production rules. For each symbol, a production rule with a matching predecessor and condition is searched. Once found, the symbol will be substituted by the parametric symbols in the successor which are evaluated using the global parameters at the current iteration and the local parameters of the symbol that is being substituted. The initial state is the axiom of the system, the state string is updated after each iteration, so the final state is specified by the arbitrary number $k$ of iterations that we have defined.
\vfill
\columnbreak
\textbf{Interpretation:} after the final state string of symbols is produced a set of interpretation rules will have to be applied to extract the information of the system. Most commonly, a geometric representation is generated by using two or three dimensional Turtle Geometry \cite{abelson1986turtle}. This translates the commands into modifications of the turtle state, which is represented by a position in space and a angle orientation in such space. Usually most modifications can be associated with euclidian affine transformation. However \emph{branching} (or \emph{bracketed}) systems will also use push and pop commands to input the current \emph{turtle state} into a stack for later recovery.
% subsection application (end)
% section background (end)

\begin{figure}[H]
  \centering
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=.63\textwidth]{trees1.png}
    \caption{}
    % \label{fig:balanced}
  \end{subfigure}%
\end{figure}
\begin{figure}[H]
\ContinuedFloat
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=.63\textwidth]{trees2.png}
    \caption{}
    % \label{fig:unbalanced}
  \end{subfigure}
  \caption{Examples of trees with ternary branching$^{\text{\cite{Prusinkiewicz:1996:ABP:235579}}}$}
   \label{fig:ttrees}\end{figure}

\section{Interdependence} % (fold)

\label{sec:interdependence}

Three dimensional parametric and stochastic L-Systems are a really powerful tool that help us model complex botanical structures such as monopodial, sympodial and ternary trees.By varying global parameters we can regulate some fixed parameters such as the way gravity affects the tree or the branching angle that the tree will follow. We can visualize these ideas in the ternary trees shown in Figure \ref{fig:ttrees}.

However, whereas we need stochastic systems as a source of variability to realistically emulate the structure of forests, there is a enormous caveat using them for multiple independent L-systems. To look into the problem lets consider the size of a state string $S$ as $|S| = L$. If each production rule translate one symbol into two and we only have deterministic production rules, the output will have size $2L$. However, if each production rule only substitutes with a $50\%$ chance then we only expect half of the symbols to change and the expected size of the output string will be $3L/2$. So we can find a proportionality between input and output sizes and this will deem an exponential growth. However, if by chance, one string gets a significantly greater or lower amount of successful production rules this will affect in the next iteration, since having more symbols in the string will allow the system to grow faster and viceversa.

This produces an oddly looking unrealistic system as we can see in Figure \ref{fig:stochas} where one of the plants has, after a few iterations grown bigger, and will keep doing so; whereas other plants have carried average iterations resulting in similar systems. This phenomenon can be justified by the fact that: a) the systems are completely independent of each other and therefore do not share any common parameters, b) we are not taking into account any real model for the shared medium, such as mineral resources.

\begin{figure}[H]
  % \centering
    \includegraphics[width=.5\textwidth]{stochastic.png}
    \caption{Simulated growth of several simple stochastic L-Systems$^{\text{\cite{Prusinkiewicz:1996:ABP:235579}}}$}
    \label{fig:stochas}
\end{figure}

In a similar fashion as \cite{KurthSloboda2002} did, we can employ  both the global parameters to the system and universal parameters to the whole group of systems to thwart this undesired behavior. These parameters display the relationship between different systems or different parts of the same system, and are usually updated after each derivation step with the information provided by different metrics on the current string state.  Depending on the locality of the parameters we can differentiate two types of dependence:
\begin{compactenum}[a)]
\item \textbf{Selfdependence} - In this case there exists a relationship between different parts of the same system. For example, given a tree whose production rules depend on the amount of light received by each branch would need to update this information after each timestep considering the shadows projected by its own branches.
\item \textbf{Interdependence} - A more complex case that involves relationships between potentially different types of L-Systems, and that reflects a reciprocal interaction between them. We can extend the previous example, given a number of trees if we consider not only the shadow of a tree to itself, but the shadow projected from other trees we will have introduced a interdependence relationship into the growth simulation.
\end{compactenum}

 Independent and selfdependent systems provide a embarrassingly parallel problem, since each system can be analyzed without considering the others they can be treated as individual problems. The load balancing can achieved by a simple manager-worker scheme using a shared queue. However, interdependent groups of L-Systems can pose a nontrivial parallelization given appropriate constraints. For this paper we have used a local resource economy which translates in the following behavior. A tree will only be affected by the trees within a radius R, which from now onwards will referred to as his \emph{neighbors}. If a tree is bigger than the average size of their neighbors then it will be harder for it to grow at the next iteration, preventing the overgrowth behavior depicted in Figure \ref{fig:stochas}. If a tree is smaller than the average size of its neighbors, then it will more likely for it to grow in the next iteration, compensating the randomness in previous iterations. We need to use this constraints since as we explained before, whereas randomness is a good source of variability for the population, it deeply alters the growth rate of different systems leading to undesired and unrealistic behaviors.

 We still need to define what the \emph{size} of a tree means from an analytical viewpoint. We will use the concept of \emph{metrics}, functions when given as an input a list of parametric symbols, output a list of real valued parameters that reflect different aspects of the system. In our implementation the metric employed measured both the number of nodes (points where branching occurs) and leaves (terminal points of the system) to account for the dimensions of the tree.
\vfill
\columnbreak
 A serial implementation of the described scenario was carried out\footnotemark. A fixed number of different L-Systems composed a given probability distribution of monopodial, sympodial and ternary trees was randomly distributed in a square surface. All these tree systems where slightly modified from the Honda canonical definitions given in \cite{Prusinkiewicz:1996:ABP:235579} to accommodate for randomness in the growth. Next, a neighbor look-up list was initialized, since neighboring relations do not change throughout the simulation. For a fixed number $k$ of iterations, each system was applied the derivation procedure and its metric recalculated and stored in a global array. Then, before starting the next iteration, the growth parameter of each system was updated using the metrics from its neighbors.

 This implementation allows for huge variability of environments. Modifying the probability distribution of trees, the size of the Area, the number of systems and the number of iterations allow us to model from old, dense boreal forests to a widely spaced savanna.

\footnotetext{All the code for this project can be found in \href{http://github.com/JJGO/Parallel-LSystem}{http://github.com/JJGO/Parallel-LSystem}}

% section interdependence (end)

\section{Parallelization} % (fold)
\label{sec:parallelization}

When looking at a decently sized group of L-Systems ($N \approx 100$) and a considerable number of iterations ($k \approx 14$), the serial implementation starts taking seconds on most modern machines. Trying to increase any of the parameters goes to the domain of minutes and even hours. Therefore, the problem can use parallelization techniques in order to reduce the computation time by introducing more processing power. For this analysis we have chosen a shared memory architecture using the OpenMP application programming interface in C++. In this paper we are going to focus in the parallelization of the derivation step for the interdependant system described in Section \ref{sec:interdependence}.

The interpretation step of multiple L-Systems is an inherently embarrassingly parallel problem since all of the systems are independent when it comes to interpretation. To further optimize the parallelization of the interpretation step, one can look at parallelizing the interpretation of an individual L-System. This can be easily done for \emph{non-branching} systems by replacing each symbol with its associated affine transformation (4x4 matrix). Since matrix multiplication is an associative operation we can easily solve the problem by using a \emph{reduce} function. \emph{Branching} systems can follow a similar approach but the complexity escapes the scope of the current paper. A more  detailed explanation can be found in \cite{LIPP-2010-PGMS}.

\subsection{Dynamic scheduling} % (fold)
\label{sub:dynamic_scheduling}

% subsection dynamic_scheduling (end)

A initial naive parallelization can be used by just simply parallelizing each one of the derivation iteration steps. Using a dynamic scheduling algorithm, the processors will evenly split the work and solve each iteration in parallel. We consider dynamic scheduling instead of static scheduling to get a better load balancing scheme. Even though we know the amount of subproblems from the start, we cannot evenly divide them into the processors since the complexity of each system will be variable due to the  stochastic formulation that the trees are following.

 As we shall see later in Section \ref{sec:results}, this approach decreases the overall time but is far from perfect. The main disadvantage associated with this approach comes from the fact that a barrier must be set up at the end of each iteration to ensure correctness. This will imply that for $p$ processors and $N$ similarly sized trees, at the end of each iteration approximately $r \equiv N \mod p$ processors will be still working and $p - r$ will be idle, waiting for the rest to finish and wasting processing power. On average, this means that half of the processors will be idle for approximately $\frac{1}{\ceil{N/p}}$ part of the time. As $p$ grows larger this fraction also becomes larger which is undesirable.

Furthermore, the presence of the two implicit \emph{barriers} per iteration in the algorithm incurs in a great overhead since all threads will be synchronized after each iteration. Therefore, if we want to optimize the algorithm we will need to reduce all of this communication to a minimum.

% subsection dynamic_scheduling (end)

\subsection{Lookahead strategy} % (fold)
\label{sub:lookahead_startegy}

Given the constraints of the problem we can enhance the parallelization by taking into account two facts:
\begin{compactenum}[a)]
\item \textbf{Local dependence} - As we explained before, the simulation has only a local dependence from a tree to its neighbors. Therefore, we need not wait for every tree to finish iteration $i$ to start iteration $i+1$. A given tree $t$ at iteration $i$ only needs the metrics of its neighbors at iteration $i$ to start the derivation phase. By applying this mechanism we can make use of every the processor available all the time; however, we will need to introduce series of constraints into the implementation.

An additional verification step must be performed to test if all the neighbors have in fact reached at least the current iteration and proceed only if the minimum of their iterations is bigger or equal the iteration of the system at hand.

The shared array that previously stored the metrics at each iteration will need another dimension for all the iterations, otherwise, we could potentially be reading a metric from a future iteration of a given neighbor, and correctness would be violated. Therefore, we will need to store for each tree $n$ the metric at every iteration $i$.

Since no two processors will try to update the same metric or iteration variable during the entire program and reading not yet updated iteration variables does not affect the correctness; we will not need mutual exclusion to modify the metric variables. Accordingly, the communication is clearly lessened to only the neighbor checking and the work scheduling.

\item \textbf{Geometry of the subproblems} - Since the simulation is running in parallel over all the $N$ trees for $k$ iterations we know in advance that $N \cdot k $ derivation steps will need to be done. We can dynamically schedule all this subproblems via an ordered work queue, so that the processors can take one subproblem at a time and if the derivation is possible (the neighbors have reached all the previous iteration) it will proceed, otherwise will return the work to the queue and try the next available subproblem.

Since we are using an approach that relies on the connectivity of the trees in the forest, we can express the neighboring relationships in the forest as a undirected graph. An arbitrary queue will render a great amount of the neighbor checking steps unsuccessful, since we cannot predict which vertices have been derived yet and which not.

However, we can make use of the inherent geometry of the problem by employing a graph traversing algorithm such as \emph{Breadth First Search}. By performing an initial \emph{BFS} traversal into the graph and storing this precalculated order we can ensure that if at every iteration, the nodes are interpreted in the same order, then we will be maximizing vertices whose neighbors all have the same iteration value.

Consequently, the algorithm will start deriving at a given starting point of the graph and traversing it following BFS. When the other end is reached, a number of processors may not have work to do in said end, so they can go back to the starting point of the graph and  with a really high probability, they will be able to derive the next iteration of the vertices there, maximizing the processing power.

\end{compactenum}

With all this optimizations the program works almost as good as before (for some inputs the neighbor checking slows the algorithm) when $p \mid N$ and much better in cases where $N \mod p$ is really small which implies that for the previous implementation, a big fraction of the processors will be idle for an entire derivation step at the end of each iteration. Since the complexity of the derivation steps grows exponentially, this enhances the simulation runtime significantly.


% subsection lookahead_startegy (end)

\subsection{Connected components optimization} % (fold)
\label{sub:connected_components}

A further optimization can be made. The main disadvantage of the solution proposed in section \ref{sub:lookahead_startegy} comes from the fact that it introduces a whole neighbor checking phase that can consume a non-negligible amount of resources if the graph presents great connectivity. Also, the simulation uses as inputs both dense and sparse groups of trees in order to satisfactorily model different types of environments. This implies that in some cases we will have a single highly connected graph and in other cases we may have several smaller subgraphs or even individual vertices.

Moreover, as we briefly commented in the previous section the neighbor checking may be unnecessary in some cases. Specifically, when all processors are executing trees in the same iteration, neighbor checking needs not be done. By using a series of flag variables we can check if all the processors are in the same iteration and skip the neighbor checking.

In addition, to improve  the algorithm we can also use the fact that we are performing a initial BFS to compute a order of visit to the vertices and also identify the different connected components of the graph. This is useful, since connected components in the graph render completely independent subgroups of L-Systems that will not share any information whatsoever during all the iterations. Using this information we can split the main queue into smaller queues which helps reducing the overhead of scheduling the work.

% subsection connected_components (end)

\subsection{Splitting L-Systems} % (fold)
\label{sub:splitting_l_systems}

To try to extend the parallelization further an attempt was made to parallelize the derivation of individual L-Systems. This rendered a problem when either $N$ was really small or $k$ was exceedingly big. To successfully divide a L-System into smaller work items, we can use the fact that L-Systems are parallel rewriting grammars. Since all the L-Systems covered in this implementation are context free, we can just evenly divide the number of symbols in the system in $m$ different pieces and add them into the dynamic queue. It is important that they are not dispersed in the queue since as we analyzed before, the neighbor checking pattern works better when given a BFS order for the nodes. The L-Systems were slightly modified to cope with the multiple updates that now a derivation step mean. The iteration value will not change until the last derivation part is finished.

Following this scheme and building on top of the previous optimizations, we successfully reached a correct solution that split the work for L-Systems when idle processors are present and directly depend on that system to continue the work with another the derivation of another systems. However, the overhead involved in both checking if one L-System is bottlenecking the derivation and maintaining a queue with both entire L-System states and partial ones rendered the solution useless since it increases the serial time by at least one order of magnitude for almost all inputs. Consequently, this implementation was not used for the final results.

% subsection splitting_l_systems (end)

% section parallelization (end)

\section{Results} % (fold)
\label{sec:results}

To thoroughly test the parallelization, the parallelization techniques described in section \ref{sec:parallelization}, were implemented incrementally and tested to test them independently. As data inputs a random combination of monopodial, system and ternary trees were used in each of the systems, all sharing the same defining parameters, since forests are usually made of trees with similar characteristics. Randomness was also use to place the points in a plane. A square surface was used, whose size was randomnly chosen at the beginning. The value for the size oscillated within the range $\sqrt{\sqrt{N}} \leq s \leq \sqrt{2N}$, since bigger sizes led to very sparse systems and smaller systems produced highly concentrated systems,  and neither of them resembled a realistic forest model. Therefore, by randomizing the area we are getting a random density for each testcase.

As we also explained in previous section randomness is a crucial part in the derivation of stochastic L-Systems. At the interpretation of every nontrivial symbol, randomness is used to decide between using the default production rule or the plain identity. This coupled with the interdependence strategy models the forest behavior as desired.

We made an analysis with numerous values for $N$ and $p$ and realized that in general, the strategies outlined in Section \ref{sub:dynamic_scheduling} and \ref{sub:lookahead_startegy} have significant improvement but the optimization outlined in section \ref{sub:connected_components} was only marginally better on average. Nevertheless, it improved the cases that were mostly affected, they just tend to happen less often with the given density model. Therefore, in the figures and plots we are going to differentiate between two cases, the initial algorithm with just sequential dynamic scheduling which will be denominated ``\emph{naive}'' and the one that takes the rest of the optimizations into account, the ``\emph{final}'' one.

\begin{table}[H]
	\centering
    \begin{subtable}{.5\textwidth}
      \centering
        \begin{tabular}{*{4}{r}}
        \textbf{p} &   \textbf{average} &       \textbf{min} &       \textbf{max} \\
            \midrule
            1 & 1.88127 & 1.25233 & 3.01181\\
            2 & 1.24117 & 0.76446 & 2.06610\\
            4 & 0.67494 & 0.42063 & 0.99662\\
            8 & 0.37431 & 0.26902 & 0.55202\\
            16 & 0.20278 & 0.11760 & 0.29165\\
            32 & 0.13674 & 0.07486 & 0.21465\\
        \end{tabular}
        \caption{N = 110 k = 12}
        \label{tab:Results_naive110}
    \end{subtable}%

    \begin{subtable}{.5\textwidth}
      \centering
        \begin{tabular}{*{4}{r}}
        \textbf{p} &   \textbf{average} &       \textbf{min} &       \textbf{max} \\
            \midrule
            1 & 3.46203 & 2.51665 & 5.24599\\
            2 & 2.41807 & 1.33393 & 3.73080\\
            4 & 1.32360 & 0.96641 & 1.92475\\
            8 & 0.68152 & 0.46520 & 1.01530\\
            16 & 0.38825 & 0.27238 & 0.54257\\
            32 & 0.25071 & 0.18171 & 0.34587\\
        \end{tabular}
        \caption{N = 220 k = 12}
        \label{tab:Results_naive220}
    \end{subtable}%
    \caption{Results for the dynamic scheduling algorithm}
    \label{tab:Results_naive}
\end{table}
\begin{table}[H]
	\centering
    \begin{subtable}{.5\textwidth}
      \centering
        \begin{tabular}{*{4}{r}}
        \textbf{p} &   \textbf{average} &       \textbf{min} &       \textbf{max} \\
            \midrule
            1 & 1.72017 & 0.97300 & 2.74679\\
            2 & 1.15123 & 0.68649 & 2.06545\\
            4 & 0.61816 & 0.42192 & 1.04124\\
            8 & 0.31979 & 0.25802 & 0.56266\\
            16 & 0.16259 & 0.13396 & 0.25908\\
            32 & 0.08555 & 0.07790 & 0.13746\\
        \end{tabular}
        \caption{N = 110 k = 12}
        \label{tab:Results_final110}
    \end{subtable}%

    \begin{subtable}{.5\textwidth}
      \centering
        \begin{tabular}{*{4}{r}}
        \textbf{p} &   \textbf{average} &       \textbf{min} &       \textbf{max} \\
            \midrule
            1 & 3.77435 & 2.30918 & 5.31532\\
            2 & 2.25018 & 1.43730 & 3.30625\\
            4 & 1.26255 & 0.93612 & 1.99715\\
            8 & 0.63661 & 0.50116 & 0.99353\\
            16 & 0.33111 & 0.26898 & 0.46761\\
            32 & 0.19841 & 0.16313 & 0.33585\\
        \end{tabular}
        \caption{N = 220 k = 12}
        \label{tab:Results_final220}
    \end{subtable}%
    \caption{Results for the final algorithm}
    \label{tab:Results_final}
\end{table}

Since adult trees require between 11 and 14 iterations to ``grow'' we have used $k = 12$ for the forests. Now, for the input sizes, we have $N = 110, 220$ which were reasonable values for formulated model. The obtained results are gathered in Tables \ref{tab:Results_naive} and \ref{tab:Results_final}. a great variety of number processors were used ($1, 2, 4, 8, 16, 32$). For a better understanding of the behavior of both algorithms the figures below depict timing results, SpeedUp and Efficiency.

\todo[inline]{Put figures}

% section results (end)

\section{Discussion} % (fold)
\label{sec:discussion}



% section discussion (end)

\section{Conclusion} % (fold)
\label{sec:conclusion}

This report explores the viability of using parametric stochastic interdependent Lindenmayer systems to model the growth behavior of a forest, and a nontrivial way of parallelizing the problem. The final parallelization scheme involved a number of components which include a dynamically scheduled queue, an initial traversal search to determine the order of the nodes, a neighbor checking algorithm that deserialized the iteration steps allowing multiple iterations happen at once and finally a decomposition of the graph into smaller subgraphs to further optimize the results.

An important conclusion that we can gather from the analysis given is the fact that the nature of the L-Systems structure was not directly used in the parallelization (except for Section \ref{sub:splitting_l_systems}, which was unsuccessful). This means that the obtained parallelization algorithm can adequately model similar problems of the same characteristics. Namely, given a simulation problem with local dependence, and problems that grow with the same complexity after each iteration; the present algorithm should render similar results with similar inputs, even if the internal elements are not precisely L-Systems.

\textbf{Future work:} The main caveat of the produced outputs was that all trees had the same ``age'', which translates in similar complexities (within one order of magnitude). This scenario is not unrealistic, (forest after fires develop in this fashion), but is far from general. We would like to analyze how the system would grow if new trees had the possibility to develop at any given iteration given certain circumstances like the presence of neighboring trees. This greatly breaks the current parallelization so it would be an interesting problem to analyze.

% section conclusion (end)


%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------
\nocite{*}
\bibliographystyle{alpha}
\bibliography{mybib}
% \begin{thebibliography}{99} % Bibliography - this is intentionally simple in this template

% \bibitem[Figueredo and Wolf, 2009]{Figueredo:2009dg}
% Figueredo, A.~J. and Wolf, P. S.~A. (2009).
% \newblock Assortative pairing and life history strategy - a cross-cultural
%   study.
% \newblock {\em Human Nature}, 20:317--330.
 
% \end{thebibliography}

%----------------------------------------------------------------------------------------

\end{multicols}

\end{document}
